{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "97c1543b_35f1ae94",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 8,
      "author": {
        "id": 1008040
      },
      "writtenOn": "2025-09-18T11:54:52Z",
      "side": 1,
      "message": "question: why explicitly naming Mongo here ? Is not Enrichment a generic feature that could be executed from any source backend to any destination backend ?",
      "range": {
        "startLine": 7,
        "startChar": 52,
        "endLine": 8,
        "endChar": 2
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "ab9f8c80_7e548cd3",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 8,
      "author": {
        "id": 1037727
      },
      "writtenOn": "2025-09-25T14:39:25Z",
      "side": 1,
      "message": "You\u0027re right. I said Mongo because it\u0027s the destination backend we used but the enrichment feature can be executed with any backend.",
      "parentUuid": "97c1543b_35f1ae94",
      "range": {
        "startLine": 7,
        "startChar": 52,
        "endLine": 8,
        "endChar": 2
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "79f715d6_9669d00a",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1019048
      },
      "writtenOn": "2025-09-17T14:35:12Z",
      "side": 1,
      "message": "Except the thread not doing any sleep, the patch is fine for me",
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0b0c5b83_6789f233",
        "filename": "rbh-fsevents/rbh-fsevents.c",
        "patchSetId": 1
      },
      "lineNbr": 397,
      "author": {
        "id": 1019048
      },
      "writtenOn": "2025-09-17T14:35:12Z",
      "side": 1,
      "message": "defect: using something like https://linux.die.net/man/3/pthread_cond_wait or a sleep here would be better, because here the thread is actively trying to dequeue for no reason, constantly working for no reason, and potentially blocking off other thread from working",
      "range": {
        "startLine": 397,
        "startChar": 12,
        "endLine": 397,
        "endChar": 21
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "5818f9cf_a0dbf1ab",
        "filename": "rbh-fsevents/rbh-fsevents.c",
        "patchSetId": 1
      },
      "lineNbr": 397,
      "author": {
        "id": 1008040
      },
      "writtenOn": "2025-09-18T11:54:52Z",
      "side": 1,
      "message": "+1 This thread condition will work with the mutex of the lock. This comment is linked with a previous comment on the previous patch : I think you need to attach a mutex per queue (instead of having only one mutex, shared and used for all queues .)",
      "parentUuid": "0b0c5b83_6789f233",
      "range": {
        "startLine": 397,
        "startChar": 12,
        "endLine": 397,
        "endChar": 21
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "8d6bcd2a_f4674eed",
        "filename": "rbh-fsevents/rbh-fsevents.c",
        "patchSetId": 1
      },
      "lineNbr": 397,
      "author": {
        "id": 1037727
      },
      "writtenOn": "2025-09-25T14:39:25Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "5818f9cf_a0dbf1ab",
      "range": {
        "startLine": 397,
        "startChar": 12,
        "endLine": 397,
        "endChar": 21
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "de42838a_0038e275",
        "filename": "rbh-fsevents/rbh-fsevents.c",
        "patchSetId": 1
      },
      "lineNbr": 439,
      "author": {
        "id": 1019048
      },
      "writtenOn": "2025-09-17T14:35:12Z",
      "side": 1,
      "message": "suggest: divide the function in 3 parts: structures init, producer loop, and structure cleaning\n\nThe function is very long currently",
      "range": {
        "startLine": 439,
        "startChar": 0,
        "endLine": 439,
        "endChar": 4
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "5d0605bb_2cb82f92",
        "filename": "rbh-fsevents/rbh-fsevents.c",
        "patchSetId": 1
      },
      "lineNbr": 439,
      "author": {
        "id": 1037727
      },
      "writtenOn": "2025-09-25T14:39:25Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "de42838a_0038e275",
      "range": {
        "startLine": 439,
        "startChar": 0,
        "endLine": 439,
        "endChar": 4
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "bcba7ca2_46f0b59e",
        "filename": "rbh-fsevents/rbh-fsevents.c",
        "patchSetId": 1
      },
      "lineNbr": 489,
      "author": {
        "id": 1008040
      },
      "writtenOn": "2025-09-18T11:54:52Z",
      "side": 1,
      "message": "suggest:\n\n```\nfor (fsevents \u003d rbh_mut_iter_next(deduplicator);\n     fsevents !\u003d NULL;\n     fsevents \u003d rbh_mut_iter_next(deduplicator)) {\n[...]\n}\n```",
      "range": {
        "startLine": 484,
        "startChar": 4,
        "endLine": 489,
        "endChar": 18
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "54bc02bc_b1ec30eb",
        "filename": "rbh-fsevents/rbh-fsevents.c",
        "patchSetId": 1
      },
      "lineNbr": 489,
      "author": {
        "id": 1037727
      },
      "writtenOn": "2025-09-25T14:39:25Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "bcba7ca2_46f0b59e",
      "range": {
        "startLine": 484,
        "startChar": 4,
        "endLine": 489,
        "endChar": 18
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6880924d_73b8b112",
        "filename": "rbh-fsevents/rbh-fsevents.c",
        "patchSetId": 1
      },
      "lineNbr": 539,
      "author": {
        "id": 1019048
      },
      "writtenOn": "2025-09-17T14:35:12Z",
      "side": 1,
      "message": "comment: it\u0027d be interesting to have the time of each worker given, that way we could see if the work is evenly distributed or if there are certains combinations of events or moments where threads take longer.\n\nBut probably only print that with a second level of verbose",
      "range": {
        "startLine": 537,
        "startChar": 8,
        "endLine": 539,
        "endChar": 50
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e4a4de6d_dfe3e4a1",
        "filename": "rbh-fsevents/src/enrichers/posix/posix.c",
        "patchSetId": 1
      },
      "lineNbr": 736,
      "author": {
        "id": 1008040
      },
      "writtenOn": "2025-09-18T11:54:52Z",
      "side": 1,
      "message": "question: is there any link between this modification and the purpose of this current patch ?",
      "range": {
        "startLine": 733,
        "startChar": 4,
        "endLine": 736,
        "endChar": 5
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "b2c6e0ae_08453f80",
        "filename": "rbh-fsevents/src/enrichers/posix/posix.c",
        "patchSetId": 1
      },
      "lineNbr": 736,
      "author": {
        "id": 1037727
      },
      "writtenOn": "2025-09-25T14:39:25Z",
      "side": 1,
      "message": "Yes, now only the consumer threads initialize an sstack, but the freeing of the sstack was handled using `__attribute__((destructor))`. This attribute is only invoked at the end of execution by the main thread (the producer). With this change, I ensure that each consumer thread frees its own sstack.",
      "parentUuid": "e4a4de6d_dfe3e4a1",
      "range": {
        "startLine": 733,
        "startChar": 4,
        "endLine": 736,
        "endChar": 5
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "62b90a3b_135c405e",
        "filename": "rbh-fsevents/src/enrichers/posix/posix.c",
        "patchSetId": 1
      },
      "lineNbr": 736,
      "author": {
        "id": 1008040
      },
      "writtenOn": "2025-09-26T08:01:04Z",
      "side": 1,
      "message": "Acknowledged",
      "parentUuid": "b2c6e0ae_08453f80",
      "range": {
        "startLine": 733,
        "startChar": 4,
        "endLine": 736,
        "endChar": 5
      },
      "revId": "abd2277f3c93986e2ec796dde921231dc0a1a2af",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    }
  ]
}