#!/usr/bin/env python3

import sqlite3
import sys
import base64
import re
import os
from typing import List
import logging
import pathlib
import json

logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler()])
logger = logging.getLogger(__name__)


class UnManagedFilter(Exception):

    def __init__(self, _filter):
        self.filter = _filter


class MissingQuotes(Exception):

    def __init__(self, _filter):
        self.filter = _filter


def remove_quotes(string: str) -> str:
    if not string[0] == '"' or not string[-1] == '"':
        return string
    return string[1:-1]


def statx_to_column(column: str) -> str:
    pattern = re.compile("^[acbm]time\\.")
    if pattern.match(column):
        return column.replace(".", "_")
    else:
        return column


class NumberLong:

    def __init__(self, value):
        self.value = int(value)


class BinData:

    def __init__(self, n, value):
        self.value = base64.b64decode(value)

    def __repr__(self):
        return f"BinData(0, '{base64.b64encode(self.value).decode('utf-8')}')"


# Compat with mongo versions
class Binary:

    @staticmethod
    def createFromBase64(value, n):
        return BinData(n, value)


def parse_filter(filters: List[str]):
    for f in filters:
        key, value = f.split(":", 1)
        key = key.strip()
        value = value.strip()

        if not key[0] == '"' or not key[-1] == '"':
            raise MissingQuotes(f)

        key = remove_quotes(key)
        if key == "ns.name":
            yield ("ns", "name", "", value)
        elif key == "ns":
            yield ("ns", "", "", value)
        elif key in ("ns.xattrs.parent", "ns.parent"):
            yield ("ns", "parent_id", "", value)
        elif key.startswith("ns.xattrs.") or key.startswith("ns.0.xattrs."):
            if key.startswith("ns.xattrs."):
                yield ("ns", "xattrs", key[len("ns.xattrs."):], value)
            else:
                yield ("ns", "xattrs", key[len("ns.0.xattrs."):], value)

        elif key.startswith("xattrs."):
            yield ("entries", "xattrs", key[len("xattrs."):], value)
        elif key.startswith("statx."):
            yield ("entries", statx_to_column(key[len("statx."):]), "", value)
        elif key == "symlink":
            yield ("entries", "symlink", "", value)
        elif  key == "_id":
            yield ("entries", "id", "", value)
        else:
            raise UnManagedFilter(f)


# TODO
# - local entry_parent="$(mongo "$testdb" --eval \
#       'db.entries.find({"ns.name":"'$entry_renamed'"},
#       {"ns.parent": 1, "_id": 0})')"
# -   local old_value=$(mongo "$testdb" --eval \
#         'db.entries.find({"xattrs.user.test":{$exists: true}},
#                          {_id: 0, "xattrs.user.test": 1})')


def resolve_mongo_types(value):
    if isinstance(value, NumberLong):
        return value.value
    elif isinstance(value, BinData):
        return value.value
    elif isinstance(value, list):
        res = []
        for v in value:
            res.append(resolve_mongo_types(v))
        return res
    else:
        return value


def eval_value(value: str):
    # mongo uses lower case true/false, replace them with uppercase versions
    value = value.replace('true', 'True')
    value = value.replace('false', 'False')
    value = value.replace('$exists', '"$exists"')
    value = value.replace('$size', '"$size"')
    value = value.replace('$regex', '"$regex"')
    # The use of _id is not consistent accross tests. Some use "_id" other
    # use _id. Mongo doesn't seem to care but we have to. We also need to make
    # sure we don't match things like mirror_id. Hence the regex.
    value = re.sub(r'([^a-zA-Z0-9_"])_id([^"])', r'\1"_id"\2', value)
    value = value.replace('\n', '')

    return resolve_mongo_types(eval(value))


def build_query(output: str, filters: List[str]):
    if output != "count(*)":
        group_by = output
        # FIXME does not work if output contains several elements
        query = f"select * from (select {output} from entries left join ns on entries.id = ns.id where "
    else:
        group_by = "entries.id"
        query = f"select count(*) from (select entries.id from entries left join ns on entries.id = ns.id where "
    data = ()

    for table, column, attribute, value in parse_filter(filters):
        v = eval_value(value)
        if isinstance(v, dict):
            if "$exists" in v:
                # Logic is reversed: exists: true means not NULL
                negate = "not " if v["$exists"] else ""
                if attribute == "":
                     continue
                query += f"json_extract({table}.{column}, '$.{attribute}') is {negate}NULL and "
            elif "$size" in v:
                if table != "ns" or column != "" or attribute != "":
                    logger.error("$size only supported for 'ns'")
                    sys.exit(1)
                query += f"entries.id in (select id from ns group by id having count(*) = ?) and "
                data = data + (v["$size"],)
        else:
            if isinstance(v, list):
                data = data + (json.dumps(v),)
            else:
                data = data + (v,)

            if table == "ns":
                query += "entries.id in (select id from ns where"

                if column in ("name", "path", "parent_id"):
                    query += f" {column} = ?"
                elif column == "xattrs":
                    query += f" json_extract(ns.xattrs, '$.{attribute}') = "
                    if isinstance(v, list):
                        query += "json(?)"
                    else:
                        query += "?"
                query += ") and "

            elif len(attribute) > 0:
                if isinstance(v, list):
                    query += f"json_extract({table}.{column}, '$.{attribute}') = json(?) and "
                else:
                    query += f"json_extract({table}.{column}, '$.{attribute}') = ? and "
            else:
                query += table + "." + column + " = ? and "

    if query.endswith(" and "):
        query = query[:-len(" and ")]
    if query.endswith(" where "):
        query = query[:-len(" where ")]

    query += f" group by {group_by})"
    return (query, data)


def nb_entries(db: str, filters: List[str]):
    with sqlite3.connect(db) as con:
        cursor = con.cursor()
        if len(filters) > 0:
            query, data = build_query("count(*)", filters)
        else:
            # With rbh-fsevents, it is possible that some entries have never
            # had an "ns_xattr" fsevent and therefore don't have a row in the
            # ns table. This means that these rows are not listed by the query
            # "entries join ns".
            query = "select count(*) from entries"
            data = ()

        res = cursor.execute(query, data)
        count = res.fetchone()
        return count[0]


def count_entries(db: str, filters: List[str]):
    count = nb_entries(db, filters)
    print(count)


def find_entry(db: str, filters: List[str]):
    count = nb_entries(db, filters)
    if count == 0:
        print("No entries found")
        sys.exit(1)
    elif count == 1:
        return
    else:
        print(f"{count} entries matching filter found")
        sys.exit(1)


def key2column(key: str) -> str:
    if key.startswith("xattrs."):
        xattr = key[len("xattrs."):]
        return f"json_extract(entries.xattrs, '$.{xattr}')"
    elif key == "_id":
        return "entries.id"
    elif key == "ns.parent":
        return "ns.parent_id"
    else:
        return key


def get_entry(db: str, filters: List[str]):
    if len(filters) not in (1, 2):
        logger.error("invalid arguments: get <filter> <output>")
        sys.exit(1)

    filter = eval_value(f"{{ {filters[0]} }}")
    if len(filters) == 2:
        output = eval_value(f"{{ {filters[1]} }}")
    else:
        # By default output the id
        output = {"_id": 1}

    filters = ('"' + key + '":' + repr(value) for key, value in filter.items())
    output = ", ".join(
        (key2column(key) for key in output if output[key])
    )
    query, data = build_query(output, filters)

    with sqlite3.connect(db) as con:
        cursor = con.cursor()
        res = cursor.execute(query, data)
        for row in res.fetchall():
            if len(row) == 1:
                if isinstance(row[0], bytes):
                    print(base64.b64encode(row[0]).decode('utf-8'), end="")
                else:
                    print(row[0], end="")
            else:
                for elem in row:
                    if isinstance(elem, bytes):
                        print(base64.b64encode(elem).decode('utf-8'), end=" ")
                    else:
                        print(elem, end=" ")
            print("")


def remove_entries(db: str, filters: List[str]):
    if len(filters) != 1:
        logger.error("invalid arguments: remove <id>")
        sys.exit(1)

    filter = eval_value(f"{{ {filters[0]} }}")
    with sqlite3.connect(db) as con:
        cursor = con.cursor()
        cursor.execute("delete from entries where id = ?",
                       (filter["_id"].value,))
        cursor.execute("delete from ns where id = ?",
                       (filter["_id"].value,))


def drop_db(db: str, filters: List[str]):
    try:
        pathlib.Path(db).unlink()
    except:
        pass


def dump_db(db: str, filters: List[str]):
    with sqlite3.connect(db) as con:
        con.enable_load_extension(True)
        con.load_extension("/usr/lib64/sqlite3/pcre.so")
        regex = ""
        if len(filters) > 0:
            if "ns.xattrs.path" in filters[0]:
                if "$regex" in filters[0]:
                    d = eval_value(f"{{ {filters[0]} }}")
                    r = d["ns.xattrs.path"]["$regex"]
                    regex = f"where json_extract(ns.xattrs, '$.path') regexp '{r}'"

        cursor = con.cursor()
        query = f"select * from entries join ns on entries.id = ns.id {regex} order by entries.id"
        res = cursor.execute(query)
        for row in res.fetchall():
            print(row)


def get_last_id(db: str, filters: List[str]):
    with sqlite3.connect(db) as con:
        query = "select last_read from readers where id = ?"
        cursor = con.cursor()
        res = cursor.execute(query, (filters[0],))
        for res in res.fetchall():
            print(res[0])


def clear_entries(db: str, filters: List[str]):
    with sqlite3.connect(db) as con:
        cursor = con.cursor()
        cursor.execute("delete from entries")
        cursor.execute("delete from ns")
        con.commit()


def db_size(db: str, filters: List[str]):
    print(os.stat(db).st_size)


def db_avgsize(db: str, filters: List[str]):
    pass

def source(db: str, filters: List[str]):
    with sqlite3.connect(db) as con:
        cursor = con.cursor()
        cursor.execute("select plugin, extensions from info")
        res = cursor.fetchone()
        print(res[0])
        for ext in json.loads(res[1]):
            print(ext)


def usage(progname: str):
    print(f"usage: {progname} <cmd> <dbname> <filter> [<filters>]")


if __name__ == '__main__':
    if len(sys.argv) < 3:
        usage(sys.argv[0])
        sys.exit(1)

    commands = {
        "count": count_entries,
        "find": find_entry,
        "get": get_entry,
        "drop": drop_db,
        "dump": dump_db,
        "size": db_size,
        "source": source,
        "avgsize": db_avgsize,
        "fsevents": get_last_id,
        "clear_entries": clear_entries,
        "remove": remove_entries,
    }

    cmd = sys.argv[1]
    if cmd not in commands:
        logger.error(f"Unknown command {cmd}")
        sys.exit(1)

    db = sys.argv[2]
    args = sys.argv[3:]

    try:
        commands[cmd](db, args)
    except UnManagedFilter as err:
        logger.error(f"unmanaged filter: {err}")
        sys.exit(1)
    except MissingQuotes as err:
        logger.error(f"missing quotes: {err}")
        sys.exit(1)
